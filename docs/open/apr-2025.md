---
title: ElfReport / Apr 2025
description: April was focused primarily on incremental performance and functional improvements to the Aarr stacks. Here some geeky stats, a retrospective, and a look ahead for ElfHosted from Apr 2025
---

# "ElfReport" for Apr 2025

During April, we made multiple, significant performance and functional improvements to the Aarr stacks, saw further features and updates applied to favorite apps like Pulsarr and SeerrBridge, and braced ourselves for the Plex-remote-streaming-pocalypse, which... hasn't really arrived.

To get us started, here are some geeky stats for Apr 2025, followed by a summary of some of the user-facing changes announced this month in the [blog](https://store.elfhosted.com/blog/)...

## Stats

=== ":seedling: Growth"

    :material-target: Focus            | :material-calendar: Feb 2025 | :material-calendar: Mar 2025 | :material-calendar: Apr 2025
    -----------------------------------|------------------------------|------------------------------|-----------------------------
    :simple-discord: [Discord][discord] members | 2495 | 2572 | 2666
    :simple-youtube: [YouTube](https://www.youtube.com/@elfhostme) subscribers | 678 | 694 | 735
    :simple-tiktok: [TikTok](https://www.tiktok.com/@elfhostme) followers | 28 | 27 | 27
    :simple-x: [X](https://x.com/elfhosted) followers | 96 | 98 | 102
    :simple-bluesky: [BlueSky](https://bsky.app/profile/elfhosted.com) followers  | - | 6 | 6
    :simple-mastodon: [Fediverse](https://mastodon.social/@elfhosted) followers  | - | 1 | 1


=== ":material-cpu-64-bit: CPU"

    The stats below illustrate CPU cores used (*not percentage*). These stats only cover the DE cluster at present, we're working on cross-cluster metrics aggregation to make this data more useful.

    Tenant CPU load on average is 5-10% higher than the preceding period, but overall CPU usage is lower due to some fixes / improvements in the supporting infrastructure components.

    ![CPU stats for Apr 2025](/images/reports/2025-04/cluster-cpu-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)
        fairy01    580m         3%       27593Mi         21%
        fairy02    1954m        12%      53447Mi         41%
        fairy03    3808m        23%      51922Mi         40%
        gretel01   1742m        14%      25316Mi         39%
        gretel02   2505m        20%      42766Mi         66%
        gretel03   222m         1%       13206Mi         20%
        gretel04   1208m        10%      45430Mi         70%
        gretel05   1083m        9%       31904Mi         49%
        gretel07   1638m        10%      25942Mi         20%
        gretel08   1089m        6%       29087Mi         22%
        gretel09   441m         2%       26763Mi         20%
        gretel10   942m         5%       24987Mi         19%
        gretel11   2762m        17%      37517Mi         29%
        gretel13   1911m        11%      20736Mi         16%
        gretel14   1275m        7%       38733Mi         30%
        gretel15   836m         5%       32720Mi         25%
        gretel16   2725m        17%      35253Mi         27%
        gretel17   813m         5%       37057Mi         28%
        gretel19   2336m        14%      30708Mi         23%
        gretel20   2230m        13%      28087Mi         21%
        gretel22   965m         6%       20195Mi         15%
        gretel23   725m         4%       31945Mi         24%
        gretel26   1262m        7%       25887Mi         20%
        gretel27   1248m        7%       16423Mi         12%
        gretel30   2775m        17%      36210Mi         56%
        gretel31   1993m        12%      36189Mi         28%
        gretel33   791m         4%       23564Mi         36%
        gretel37   1585m        9%       22062Mi         17%
        hansel01   1152m        9%       24158Mi         37%
        hansel02   1296m        10%      28245Mi         44%
        hansel04   928m         7%       23501Mi         36%
        hansel05   1705m        14%      23604Mi         36%
        hansel06   1277m        10%      26652Mi         41%
        hansel07   2821m        23%      25423Mi         39%
        hansel08   1056m        8%       25979Mi         40%
        hansel14   1447m        12%      37012Mi         57%
        hansel15   3867m        32%      47671Mi         74%
        hansel16   889m         7%       23476Mi         36%
        hansel17   1143m        9%       30925Mi         48%
        hansel18   1042m        8%       24270Mi         37%
        hansel20   1028m        8%       25540Mi         39%
        ```

    Last month (*Mar*)'s for comparison:

    ![CPU stats for Mar 2025](/images/reports/2025-03/cluster-cpu-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)
        fairy01    657m         4%       25041Mi         19%
        fairy02    2033m        12%      54269Mi         42%
        fairy03    1788m        11%      40922Mi         31%
        gretel01   2971m        24%      28806Mi         44%
        gretel02   337m         2%       15937Mi         24%
        gretel03   145m         1%       9942Mi          15%
        gretel04   801m         6%       23121Mi         36%
        gretel07   360m         2%       21299Mi         16%
        gretel08   721m         4%       32298Mi         25%
        gretel09   459m         2%       21648Mi         16%
        gretel10   4242m        26%      58585Mi         45%
        gretel11   1210m        7%       32423Mi         25%
        gretel13   3241m        20%      30307Mi         23%
        gretel14   7668m        47%      40425Mi         31%
        gretel15   2799m        17%      29300Mi         22%
        gretel16   1859m        11%      22386Mi         17%
        gretel17   3755m        23%      32923Mi         25%
        gretel19   2537m        15%      80640Mi         62%
        gretel20   1937m        12%      28771Mi         22%
        gretel22   898m         5%       25351Mi         19%
        gretel23   2151m        13%      37010Mi         28%
        gretel26   2211m        13%      25469Mi         19%
        gretel27   2321m        14%      25358Mi         19%
        gretel30   987m         6%       23808Mi         37%
        gretel31   607m         3%       25442Mi         19%
        gretel33   2340m        14%      20301Mi         31%
        gretel37   3997m        24%      45488Mi         35%
        hansel01   1104m        9%       27231Mi         42%
        hansel02   2191m        18%      23370Mi         36%
        hansel04   713m         5%       27569Mi         42%
        hansel05   1446m        12%      17211Mi         26%
        hansel06   1651m        13%      23849Mi         37%
        hansel07   2341m        19%      25620Mi         39%
        hansel08   1369m        11%      22478Mi         35%
        hansel14   1909m        15%      27661Mi         43%
        hansel15   1249m        10%      43481Mi         67%
        hansel16   751m         6%       19163Mi         29%
        hansel17   705m         5%       19594Mi         30%
        hansel18   974m         8%       19538Mi         30%
        hansel20   1383m        11%      25043Mi         39%
        ```

=== ":material-memory: RAM"

    This graph represents memory usage across the entire (DE) cluster. Tenant RAM usage has increased by ~20%, while CPU usage only increased 5-10%, which may be a result of the Aarr SQLite-to-PostgreSQL migration detailed below.

    Other high consumers of RAM:

    * **csi-rclone**: used for mounting all rclone-compatible storage mounts, primarily RealDebrid libraries
    * **kube-system**: the Kubernetes control plane, including the cilium agents which manage the networking / policy enforcement (*currently 11K flows/s across 30 nodes*)
    * **traefik**: all inbound access to the cluster / services
    * **[mediafusion][mediafusion]**: an excellent (*but RAM-hungry!*) [Stremio addon](/stremio-addons/)

    ![Memory stats for Apr 2025](/images/reports/2025-04/cluster-memory-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)
        fairy01    580m         3%       27593Mi         21%
        fairy02    1954m        12%      53447Mi         41%
        fairy03    3808m        23%      51922Mi         40%
        gretel01   1742m        14%      25316Mi         39%
        gretel02   2505m        20%      42766Mi         66%
        gretel03   222m         1%       13206Mi         20%
        gretel04   1208m        10%      45430Mi         70%
        gretel05   1083m        9%       31904Mi         49%
        gretel07   1638m        10%      25942Mi         20%
        gretel08   1089m        6%       29087Mi         22%
        gretel09   441m         2%       26763Mi         20%
        gretel10   942m         5%       24987Mi         19%
        gretel11   2762m        17%      37517Mi         29%
        gretel13   1911m        11%      20736Mi         16%
        gretel14   1275m        7%       38733Mi         30%
        gretel15   836m         5%       32720Mi         25%
        gretel16   2725m        17%      35253Mi         27%
        gretel17   813m         5%       37057Mi         28%
        gretel19   2336m        14%      30708Mi         23%
        gretel20   2230m        13%      28087Mi         21%
        gretel22   965m         6%       20195Mi         15%
        gretel23   725m         4%       31945Mi         24%
        gretel26   1262m        7%       25887Mi         20%
        gretel27   1248m        7%       16423Mi         12%
        gretel30   2775m        17%      36210Mi         56%
        gretel31   1993m        12%      36189Mi         28%
        gretel33   791m         4%       23564Mi         36%
        gretel37   1585m        9%       22062Mi         17%
        hansel01   1152m        9%       24158Mi         37%
        hansel02   1296m        10%      28245Mi         44%
        hansel04   928m         7%       23501Mi         36%
        hansel05   1705m        14%      23604Mi         36%
        hansel06   1277m        10%      26652Mi         41%
        hansel07   2821m        23%      25423Mi         39%
        hansel08   1056m        8%       25979Mi         40%
        hansel14   1447m        12%      37012Mi         57%
        hansel15   3867m        32%      47671Mi         74%
        hansel16   889m         7%       23476Mi         36%
        hansel17   1143m        9%       30925Mi         48%
        hansel18   1042m        8%       24270Mi         37%
        hansel20   1028m        8%       25540Mi         39%
        ```

    Last month (*Mar 2025*)'s for comparison:

    ![Memory stats for Mar 2025](/images/reports/2025-03/cluster-memory-utilization.png)

    ??? "kubectl top nodes"
        ```
        NAME       CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)
        fairy01    657m         4%       25041Mi         19%
        fairy02    2033m        12%      54269Mi         42%
        fairy03    1788m        11%      40922Mi         31%
        gretel01   2971m        24%      28806Mi         44%
        gretel02   337m         2%       15937Mi         24%
        gretel03   145m         1%       9942Mi          15%
        gretel04   801m         6%       23121Mi         36%
        gretel07   360m         2%       21299Mi         16%
        gretel08   721m         4%       32298Mi         25%
        gretel09   459m         2%       21648Mi         16%
        gretel10   4242m        26%      58585Mi         45%
        gretel11   1210m        7%       32423Mi         25%
        gretel13   3241m        20%      30307Mi         23%
        gretel14   7668m        47%      40425Mi         31%
        gretel15   2799m        17%      29300Mi         22%
        gretel16   1859m        11%      22386Mi         17%
        gretel17   3755m        23%      32923Mi         25%
        gretel19   2537m        15%      80640Mi         62%
        gretel20   1937m        12%      28771Mi         22%
        gretel22   898m         5%       25351Mi         19%
        gretel23   2151m        13%      37010Mi         28%
        gretel26   2211m        13%      25469Mi         19%
        gretel27   2321m        14%      25358Mi         19%
        gretel30   987m         6%       23808Mi         37%
        gretel31   607m         3%       25442Mi         19%
        gretel33   2340m        14%      20301Mi         31%
        gretel37   3997m        24%      45488Mi         35%
        hansel01   1104m        9%       27231Mi         42%
        hansel02   2191m        18%      23370Mi         36%
        hansel04   713m         5%       27569Mi         42%
        hansel05   1446m        12%      17211Mi         26%
        hansel06   1651m        13%      23849Mi         37%
        hansel07   2341m        19%      25620Mi         39%
        hansel08   1369m        11%      22478Mi         35%
        hansel14   1909m        15%      27661Mi         43%
        hansel15   1249m        10%      43481Mi         67%
        hansel16   751m         6%       19163Mi         29%
        hansel17   705m         5%       19594Mi         30%
        hansel18   974m         8%       19538Mi         30%
        hansel20   1383m        11%      25043Mi         39%
        ```

=== ":material-server-network: Network"

    Network usage during the snapshot period has increased from last month's snapshot, but given the changing nature of traffic patterns across the day / week, it's not possible to reach any conclusions about the changes from month-to-month. Rather, the graphs below indicate that our nodes are not contending for network throughput, and our per-tier egress rate-limits are being correctly enforced.
    
    !!! tip "Why Hansel & Gretel?"
        Bundles are datacenter-agnostic, but nodes are specific to each datacenter, and we needed a way to differentiate US nodes from DE nodes. The fairy tale of [Hansel and Gretel](https://en.wikipedia.org/wiki/Hansel_and_Gretel) originates in Germany :flag_de:

    ![Network traffic for Apr 2025 (*hansels*)](/images/reports/2025-04/cluster-network-utilization-hansels.png)
    
    ![Network traffic for Apr 2025 (*gretels)](/images/reports/2025-04/cluster-network-utilization-gretels.png)

    Last month (*Mar 2025*)'s for comparison:

    ![Network traffic for Mar 2025 (*hansels*)](/images/reports/2025-03/cluster-network-utilization-hansels.png)

    ![Network traffic for Mar 2025 (*gretels)](/images/reports/2025-03/cluster-network-utilization-gretels.png)

## Retrospective

### Decypharr

Originally [announced in Mar 2025](https://store.elfhosted.com/blog/2025/03/27/decypharr-debridav-now-ga-symlink-cleaner-in-beta/), April saw us [bravely pivot](https://store.elfhosted.com/blog/2025/04/30/decypharr-beta-boosts-brilliantly-for-early-adopters/) to the "beta" branch of Decypharr, for improved config editing via the UI, and WebDAV support, which means that **Decypharr can now be used as a replacement for Zurg**.

!!! question "What's wrong with Zurg?"
    Nothing, it's more about what's wrong with **you** :stuck_out_tongue: - Currently, when Zurg detects changes to your RD library, it initiates a full refresh, which can take time - several minutes, on larger libraries. During this time, the contents of the RD folder are not refreshed, and so automated download tools (like.. decypharr) sit around for several minutes waiting for each "downloaded" item to appear in your RD mount.

    Since Decypharr's doing the downloading anyway, replacing Zurg with Decypharr makes this process totally internal, and thus Decypharr **instantly** "downloads" the target media, bypassing the zurg refresh-delay.

See more details in [this blog post](https://store.elfhosted.com/blog/2025/04/30/decypharr-beta-boosts-brilliantly-for-early-adopters/).

### PostgreSQL

During April we carefully transition all our Radarr / Sonarr / Prowlarr instances from their native SQLite support, to PostgreSQL (*also native, but running independently of the Aarr*). Just like the Decypharr update above, this update was motivated by some of the "heavy-hitters", whose Aarr libraries were starting to slow down and thrash CPU based on the single-threaded nature of SQLite. 

Here to explain it more elegantly than I, is ChatGPT:

> When Radarr queues a hundred shows,
> And Sonarr scans where content goes,
> SQLite may start to groan and stallâ€”
> A single thread canâ€™t do it all.
> 
> But PostgreSQL, with power wide,
> Handles locks and reads with pride,
> Concurrency it does embrace,
> With queries flyingâ€”grace and pace.
> 
> So if your media starts to sprawl,
> And file scans echo through the hall,
> Let Postgres take the backend loadâ€”
> A smoother, faster data road.

More details in [this blog post](https://store.elfhosted.com/blog/2025/04/14/bulk-up-your-aars-with-postgresql/).

### "The shim"

No, it's not a prison-fighting tool (*that's a "shank"*), and it's not a "she/him=shim" gender thing... in our case, it's a clever way to "trick" the Aars into processing symlinked debrid downloads without having to "ffprobe" each one, saving bandwidth and time when processing a large queue.

This time, I asked ChatGPT to rap a technical explanation for you:

> (Beat drops...)
> ðŸŽ¤ Yo, listen up now, let me make this clear,
> We talkinâ€™ 'bout shims, so lend me your ear.
> It ainâ€™t a gender thing, donâ€™t get it twisted,
> Not a prison shank, so scratch that off your wishlist.
> 
> A shim in techâ€”yo, itâ€™s kinda sly,
> It slides in the middle when code goes awry.
> Itâ€™s a little piece of code, fills in the gap,
> Makes old stuff work with the new, no cap.
> 
> You got a program lookinâ€™ for an old API?
> But your system changed and said â€œGoodbyeâ€?
> Thatâ€™s where a shim steps in on cueâ€”
> Talks to both sides like a tech guru.
> 
> So next time someone says â€œI threw in a shim,â€
> Donâ€™t look confused, and donâ€™t think grim.
> Itâ€™s just a smart fix, a compatâ€™ layer winâ€”
> Helping software talk, like it always been.

More details in [this blog post](https://store.elfhosted.com/blog/2025/04/04/super-charge-your-aars-with-the-shim/).

### Huntarr

Huntarr is a clever new tool which plugs yet-another gap in the Aaar workflow - it looks at your Aarr libraries, and "hunts" missing content. While this role was previously fulfilled by Scanarr (*shoutout to [Puks The Pirate](https://github.com/Pukabyte/scannarr)*), we've put Scannarr to bed and fully embraced the Huntarr!

All ElfHosted Aar users get Huntarr built into their bundles.

More details in [this blog post](https://store.elfhosted.com/blog/2025/04/25/huntarrs-evolved-v5-arr-dbs-stablized/)

### Byparr

Flaresolverr is (was?) a tool for automatically "solving" CloudFlare CAPTCHAs employed by some indexers, so that automated tools like [Prowlarr][prowlarr] and [Jackett][jackett] can scrape them without human intervention. Flaresolverr hasn't worked well for a while now, and is unlikely to ever do so again.

[Byparr](https://github.com/ThePhaseless/Byparr) is a modern, drop-in replacement for Flaresolverr. We've "dropped it into" all the Flaresolverr bundles, so where you see `flaresolverr` in ElfHosted, it's actually Byparr, behind the scenes.

The change from Flaresolverr to Byparr has also allowed us to allocate less resources for "Flaresolverr", so you'll notice that it's now included by default with all Hobbit bundles (*previously only Ranger+*).

More details in [this blog post](https://store.elfhosted.com/blog/2025/04/16/byparr-bypasses-flaresolverr/).

### SeerrBridge

We announced [SeerrBridge][seerrbridge] support last month, but the dev dropped a significant update in response to user requests - it's now possible to use SeerrBridge with **ongoing** TV shows, a huge QOL improvement for our initial beta-testers.

More details in [this blog post](https://store.elfhosted.com/blog/2025/04/03/pulsarr-and-seerrbridge-get-supercharged/).

### Bundles Simplified

We've switched the format of the streaming bundles in the store over to "variable" products, which means that instead of 50+ possible product variations, there are now [only 6 streaming bundles](https://store.elfhosted.com/product-category/streaming-bundles/), each of which can be customized for your preferred media player, cloud provider, and media automation (*existing subscriptions unaffected*).

In order of increasing awesomeness, and now with nice and easy-to-remember URLs, these are:

1. [Zurglings](https://store.elfhosted.com/product/zurgling) (*contended, no automation*)
2. [Starters](https://store.elfhosted.com/product/starter) (*contended*)
3. [Hobbits](https://store.elfhosted.com/product/hobbit) (*semi-dedicated*)
4. [Rangers](https://store.elfhosted.com/product/ranger) (*semi-dedicated*)
5. [Halflings](https://store.elfhosted.com/product/halfling) (*semi-dedicated*)
6. [Nazguls](https://store.elfhosted.com/product/nazgul) (*dedicated*)

All bundles come with your choice of [Plex][plex] (*PlexPass required*), [Emby][emby], or [Jellyfin][jellyfin], can be managed (*except Zurglings*) by either [Riven][riven], [SeerrBridge][seerrbridge], [plex_debrid][plex-debrid], [cli_debrid][cli-debrid], or [Radarr][radarr]/[Sonarr][sonarr]/[Prowlarr][prowlarr], and support RealDebrid, AllDebrid (*VPN required*), Premiumize and EasyNews (*app-dependent*).

### Mooar Apps

#### List-Sync

[List-Sync][list-sync] "feeds" your [OverSeerr][overseerr] / [JellySeerr][jellyseerr] with content from Trakt, IMDB, or Letterboxd lists, allowing you to sync your libraries with your own (*or other public*) lists.

#### Letterboxd Trakt Sync (beta)

This one was added in response to a request from an Elfie - Need to sync your Letterboxd "diary" with your Trakt account? There's an [app for that](https://store.elfhosted.com/product/letterboxd-trakt-sync/)!

#### Profilarr (beta)

A long-time [EEP](https://github.com/elfhosted/enhancements/issues/32), [Profilar](https://store.elfhosted.com/product/profilarr/) is a UI-based tool to manage quality profiles in the Aars. 

Initial testing by @Layezee20 has been very positive, and if you're an early adopter who's interested in fine-tuning your Aar quality profiles, this may bring you hours of delight!

No documentation yet, but it's follow-your-nose easy, with a subscription available [here](https://store.elfhosted.com/product/profilarr/).
  
#### AudioBookBayAutomated (beta)

[AudioBookBay Automated](https://store.elfhosted.com/product/audiobookbay-automated/) is another [bleeding-edge](https://github.com/JamesRy96/audiobookbay-automated) app which needs testing, but if you're an audiobook-phile, it may tweak your interest...

![](/images/screenshots/audiobookbayautomated.png)

## Coming up

### US East Coast DC

It turns out that part of the delay in establishing our PA site has been related to the hardware supplier of the equivalent configurations we're using in the west-coast site, (elfhosted.cc). After some back-and-forth with our friends at Crunchbits, we've decided to pivot, and invest more heavily in the PA site, owning our own hardware outright, and scaling up capacity by 200-300%.

The appropriate :fire: has been lit, and we're getting high-priority, VIP treatment with a mind to establish the PA site by the end of May! :fingers_crossed:

### Symlink Cleaner

Our very own ElfVenger, @BSM, has been working on a new, Elf-sclusive app, cleverly named "Symlink Cleaner" (*he took a break during much of April for IRL responsibilities!*) Symlink Cleaner is currently available free as an [early-access trial](https://store.elfhosted.com/product/symlink-cleaner-early-access/), after which time we intend to roll it out to all Elfies, free of charge.

![](/images/screenshots/symlink-cleaner.png)

### Even mooar apps

Apps currently requested can be found (and submitted!) [here](https://github.com/elfhosted/enhancements/issues?q=sort%3Aupdated-desc+is%3Aissue+is%3Aopen)

Notable suggestions:

* [TitleCardMaker](https://titlecardmaker.com/) (*CLI version for now*)

### Your ideas?

Got ideas for improvements? Send us an EEP (*ElfHosted Enhancement Proposal*) [here](https://github.com/elfhosted/enhancements/issues/new/choose)!

## How to help

Another effective way to help is to drive traffic / organic discovery, by mentioning ElfHosted in appropriate forums such as Reddit's [r/plex](https://reddit.com/r/plex),  [r/realdebrid](https://reddit.com/r/realdebrid), and [r/StremioAddons](https://reddit.com/r/StremioAddons), which is where much of our target audience is to be found!

## Join us!

!!! tip "Want to get involved?"

    Want to get involved? Join us in [Discord][discord]!

--8<-- "common-links.md"

{% include 'testimonials.md' %}